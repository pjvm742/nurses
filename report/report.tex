\documentclass{article}

\usepackage[boxed,vlined]{algorithm2e}

\usepackage[maxbibnames=30,backend=biber]{biblatex}
\addbibresource{refs.bib}

\usepackage{graphicx}

\title{An algorithm for the nurse rostering problem}

\author{P van Mill, D van Boxtel}

\date{June 2023 \\
Course: Operations research applications \\
Maastricht University}

\begin{document}
\maketitle

\section{Introduction}

In the rapidly developing world we live in today our progressing health is among the things has given rise to some challenges.
For example, one notable challenge that countries currently grapple with is the substantial pressure exerted on pension funds.
This is a direct result of the fact that our life expectancy is increasing because of the prosperity of the society.
Another sector facing considerable difficulties is the health care industry and in particular personnel management.
As patients often require care around the clock effective deployment of the personnel is important to be able maintain high-quality patient care.

A key part to the optimization of the deployment of the personnel is the rostering of nurses.
This has proven to be a strenuous problem to tackle in practice.
Next to the fact that rosters often have as a necessity to be covered around the clock, there are no days throughout the year that demand comes to a halt.
Furthermore, there are a multitude of constraints and preferences involved.
It is desirable to take as many of these in regard when creating a roster as they are crucial to maintaining staff satisfaction, minimizing cost and staying in line with government regulations.

Over the years, various approaches have been proposed to address the nurse rostering problem however it has not received as much attention as it deserves.
This has caused researchers to write out competitions to garner more interest for the optimization problem of nurse scheduling.
One such competition is the International Nurse Rostering Competition of 2010 (INRC2010, see \cite{inrc}).
The most important goal of this competition was to foster new approaches to the problem at hand by attracting participants from diverging research fields.
Next to this the competition aimed t close the gap between research practice for this important topic.

The competition has resulted in some interesting results and approaches to the specific problem instances of the competition.
Valouxis et al used a two phase approach where the focus of the first phase was on the assignment of working days and the second stage focused on the assignment of specific daily shifts\cite{Valouxis}.
This was then combined with several swap operators that searched across combinations of nurses' partial schedules.
Such local search operators are common when looking at different approaches to the competition.
Abuhamdah et al used a population based local search that also uses different operators\cite{Abuhamdah}.

This paper proposes an innovative approach to the nurse rostering problem that can be described as a large neighborhood search that is guided by soft constraints.
Large neighborhood search is a method where complex neighborhoods are searched using heuristics. It enables researchers to explore better solutions throughout the search process.
Heuristics based on large neighborhood search have shown to be very useful in approaching scheduling problems in past research\cite{Pisinger}. 
The algorithm in this research creates an initial feasible schedule according to the hard constraints and searches the solution space for improvements using the soft constraints.
To assess the effectiveness of the proposed approach, we conduct experiments using the instances provided by the INRC2010 and compare them to the optimal solutions that have been found so far. 

The structure of this paper is as follows: in the beginning we will explain the problem at hand.
We will take a look at the different constraint and instances of the competition.
The next part presents the proposed algorithm and its implementation for use on the problem instances.
After this we describe the experimental setup and discusses the obtained results.
Finally, the paper concludes with a conclusion and some remarks on possible improvements and future research.

\section{Problem description}
The problem set out by the competition is built up as follows.
A planning period is specified along with shift types, the day and shift requirements, and the different types of contracts that nurses can have.
In these contracts the working regulations of the nurses are stated.

The problem consists of a number of constraints that have been divided into hard and soft constraints.
The hard constraints are the constraints that have to be respected for a schedule to be considered feasible.
The soft constraints represent preferences of the nurses, union rules and government regulations.

For the hard constraints we have that shift requirements must be met, that means every demanded shift must be assigned to a nurse, and the constraint that every nurse can work only one shift per day.
Not violating these constraints leads to a feasible schedule.

There are many more soft constraints that range from working a maximum or minimum number of days in a row to specific requests for days of shifts.
The soft constraints considered in the problem are the following:

\begin{itemize}
	\item a maximum/minimum number of total assigned shifts
	\item a maximum/minimum number of consecutive assigned shifts
	\item a maximum/minimum number of consecutive free days 
	\item a maximum/minimum number of consecutive working weekends
		(a weekend is regarded as a working weekend if the nurse is assigned to a shift at least one day of the weekend)
	\item that nurses are only assigned to shifts for which they have the required skills
	\item that nurses to work complete weekends
		(this means that if a nurse works in a weekend, they should work on all the days of that weekend)
	\item that identical shift types are assigned on all days of a weekend
	\item that no night shifts assigned to a nurse before a free weekend
	\item that nurses are not assigned on day or specific shifts for which they have submitted an off request
	\item that certain patterns should not appear in the schedule
\end{itemize}

Now to be able to distinguish different schedules in terms of solution quality, the soft constraint violations are checked.
For constraints with an integer target (i.e. the "maximum/minimum" constraints), the violation value is taken as the difference with the target; forthe other constraints, which are binary, the violation value is either 0 or 1.
In every instance of the problem and in every different contract, the constraints are assigned certain weights.
The objective value of a solution is the weighted sum of the violation values for every constraint and for every nurse.

It should be noted that there are some decisions to be made in how the constraint violations are calculated.
For example, for the "minimum consecutive" constraints, it makes quite a difference whether sequences at the edges of the planning period are taken into account.
Arguably, it is incorrect to do so, as the schedule before the planning period and after is unknown and it cannot be said whether the minimum consecutive number is met.
However, in this case we have decided count this after all, because most researchers seem to do so.

\subsection{Notes on the competition}

The problem instances are divided into three different levels of difficulty: the sprint, medium and long instances.
The competition classified them as such because they were permitted different amounts of running time.
In the competition, sprint instances were allowed 10 seconds of running time, medium instances 10 minutes and long instances 10 hours.
The instances are provided as XML files.

The problem description is somewhat more general than the problems actually represented in the instances.
In particular, the demands for the days are regular with a period of one week; thus, in practice the occurence of special days with irregular demands is not modeled in the problem.

Relatedly, there are some inconsistencies in the competition between the list of constraints, the given XML schema and the actual instances.
Specifically, we have not considered the constraints "two free days after a night shift" and "maximum number of working weekends in four weeks" as part of the problem, because these are not used in any of the instances.

\section{Approach}
\subsection{Algorithm}

\begin{table}
\begin{algorithm}[H]
\DontPrintSemicolon
	\KwData{a set of nurses $N$, a set of days $D$ and shift types $T_{shift}$, requirement for each shift type on each day $r_{s,d}$, and a set $C$ of soft constraints}
\KwResult{the best schedule $S$ found}
	\While{there is running time left}{
		let $S'$ be a copy of the current solution S \;
		choose the $k_N$ and $k_C$ for this iteration \;
		randomly select $N^{destroy} \subset N$ with $|N^{destroy}| = k_N$ \;
		randomly select $C^{destroy} \subset C$ with $|C^{destroy}| = k_C$ \;
		\For{all nurses $i \in N^{destroy}$}{
			\For{all constraints $c \in C^{destroy}$}{
				eliminate all violations of constraint $c$ from $S'_i$ \;
			}
		}
		\For{each day $d \in D$}{
			let $N_{s,d}$ be the set of nurses assigned to shift type $s$ on day $d$ \;
			let $n_{s,d} = |N_{s,d}|$ \;
			\While{$\exists s : n_{s,d} > r_{s,d}$}{
				let $i^* \in N_{s,d}$ be the nurse for whom removing the assignment will reduce soft constraint violations the most \;
				$S'_{i^*,d} \gets s_{off}$ \;
			}
			\While{$\exists s : n_{s,d} < r_{s,d}$}{
				let $i^* \in N_{s_{off},d}$ be the nurse for whom assigning $s$ will increase soft constraint violations the least \;
				$S'_{i^*,d} \gets s$ \;
			}
		}
		\If{$objective_C(S') \leq objective_C(S)$}{
			$S \gets S'$ \;
		}
	}
\end{algorithm}
	\caption{Pseudocode for our base algorithm}
	\label{pseudocode}
\end{table}

Table \ref{pseudocode} shows the pseudocode for our algorithm.
It should be noted, as we have made this implicit, that each time something is done for all elements of a set, the order is randomised.

The algorithm can be described as a large neighborhood search guided by soft constraints.
Specifically, it uses one (parameterised) destroy operator and one repair operator, and both are based on the soft constraints.
The goal behind the algorithm was to create something original, yet also a relatively simple solution approach that could be readily understood.

After initializing a feasible solution, a certain number $k_N$ of nurses and $k_C$ of constraints are chosen.
For these nurses the constraints are consecutively enforced.
Enforcing here is meant in the sense of removing all violations of this constraint for the specific nurse by either assigning or unassigning shifts to nurses.
After this process the remaining schedule is not feasible anymore.
To get back to a feasible solution we have to repair the schedule. 
We look through all the days in a random order.
If the shift requirements are currently not met on a day (either to many shifts are assigned or not enough shifts are assigned), we fix it by either assigning shifts of removing shifts.
This assigning or removing shifts to nurses is done by looking at the impact the change would have on the total penalty value of a nurse.
Assigning or removing shifts is done to the nurse whose penalty value it will increase the least or reduce the most (it should be noted here that these are equivalent: it can happen that assigning a shift reduces the penalty value, or that unassigning one increases it).

After these operations, when the schedule has been made feasible again, the solution value is calculated.
If the new schedule leads to a better solution value, the current schedule is adjusted to this better version and we start the process again.

For our initial solution, we simply run our repair operator on an empty schedule.

\subsubsection{Variants}

In the base algorithm, we use a constraints-based repair operator.
For comparison, we also implemented a random repair operator, which, for each insertion or deletion, simply selects a nurse randomly among the possible nurses, instead of basing the choice on the soft constraints.

Left unspecified in the pseudocode is how to choose $k_N$ and $k_C$.
Here we considered two variants.
In the first variant, $k_N$ and $k_C$ are simply the same for every iteration and are fixed at $\Bigl \lceil \frac{|N|}{3} \Bigr \rceil, \Bigl \lceil \frac{|C|}{3} \Bigr \rceil$.

In the second variant, we use a dynamically updating joint distribution for the $k$s.
Specifically, each combination $(k_N,k_C)$ is chosen with the pseudo-probability:
$$\frac{n_{successes}+1}{(n_{tries}+1) (k_N \cdot k_C)}$$
... essentially the expected success probability divided by a proxy for the amount of effort that the iteration is expected to take ($k_N \cdot k_N$).
This pseudo-probability distribution of course has to be normed to sum to one, then it is an actual probability distribution.

There are also some choices to be made in how to enforce constraints and how to evaluate the impact of a change.
For the constraints enforcement, we have not done too much special; we have only made sure that if some shifts are to be assigned or removed within some range, that this is done spread evenly across the range.

For the impact evaluation on the other hand, we have made two quite different versions.
In the first version, the impact corresponds as closely as possible to how much the penalty value will change as a result of the assignment or removal.
In the second, looser version, this is much less the case.
In particular, in the looser version, the constraint contribution for a sequence that exceeds a "maximum consecutive" constraint is the same no matter the length of the sequence and no matter the position of the particular day in the sequence.
For "minimum consecutive" constraints on the other hand, the impact evaluator encourages every too-short sequence to be completely eliminated and never incentivises making it longer; this is somewhat counter-intuitive as it may well report a reduction in the penalty value when the actual impact is an increase.

\subsection{Implementation}

The algorithm was implemented in the Java programming language.
Our code is available at \texttt{https://github.com/pjvm742/nurses}.

To extract the information from the instances we make use of the XML parser of Duysak, Karzel and Schmitt \cite{DKS}.
We then further process the instance information into our own formats.
The solution schedule is represented as a two dimensional N x D matrix, which automatically enforces the hard constraint that every nurse can only be assigned to one shift on each day.
The rowns correspond to the nurses and the columns to the days in the planning period.
The entries in the matrix resemble the shift that is assigned to a nurse on a specific day.
A zero entry means a nurse has a day off and the shift types in an instance are numbered to represent the other entries where a shift is assigned to a nurse.

We also tried to validate our code for the soft constraints evaluation against that of Duysak et al.
This allowed us to find one critical error in the "minimum consecutive" constraints that changed all our results.
We did not find any other errors; however, our solution values are still different from those of Duysak et alia and, as we shall see, also different from those of the competition organisers.

\section{Results}

We did some tests to try and determine the added value of various components of our algorithm.
We perform these tests on the "long" instances, where the differences are best visible, with time allowances of 10 and 30 seconds.

Firstly, we tested the added value of the dynamically updating distribution for $k_N$ and $k_C$.
As a baseline, we take the version with fixed $k_N$ and $k_C$ and the random repair operator.
On average, replacing this component resulted in a relative decrease in the objective value of about 10\%, although for some instances there is instead an increase.
More importantly, the version with dynamic $k$s seems to make much better use of more time.

Next we try to test the added value of two versions of the constraints-guided repair operator, one which corresponds more strictly to the contribution towards the penalty value, and one which corresponds less cleanly (see section "Variants").
As a baseline, we take the version with the random repair operator, everywhere using the dynamic $k$s.
Interestingly, the strict version of the constraints-guided repair operator seems to only make things worse, by about 7\% on average.

The less strictly corresponding version of the constraints-guided operator seems to be equally matched with the random operator for time allowances of 10 and 30 seconds, giving a worse result about as often as it gives a better result.
The added value of this component remains unclear, but for the rest of the results, we use this repair operator as specified in our base algorithm, rather than switch to the random repair.

Next, how well does our algorithm perform?
To investigate this, we ran our algorithm on a few representative instances, for varying amounts of time.
In light of our goal to make a fast algorithm, we only used running times under 5 minutes.
Table \ref{results} shows the average objective values obtained, with the sample standard deviations.
For running times of 10 through 90 seconds, the sample size is 8; for 270, the sample size used was 3.

Unfortunately, due to inconsistencies in the constraint evaluation, these results are difficult to compare to those of other authors.
However, it seems that in most cases our algorithm performs reasonably well.

\begin{table}
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		instance & 10 s & 30 s & 90 s & 270 s & best known \\
		\hline
		long early 1 & 273 & 254 & 223 & 209 & 197 \\
		& 22.4 & 19.2& 8.5 & 5.6 & \\
		\hline
		long late 1 & 183 & 167 & 138 & 128 & 235 \\
		& 12.8 & 13.3 & 7.5 & 7.2 & \\
		\hline
		long hidden 1 & 1393 & 1141 & 965 & 787 & 346 \\
		& 68.3 & 67.1 & 51.5 & 37.8 & \\
		\hline
		medium early 1 & 273 & 265 & & & 240 \\
		& 5.46 & 5.60 & & & \\
		\hline
		medium late 1 & 121 & 105 & & & 157 \\
		& 19.2 & 9.9 & & & \\
		\hline
		medium hidden 1 & 878 & 592 & & & 111 \\
		& 94.2 & 38.7 & & & \\
		\hline
		sprint early 1 & 52 & 49 & & & 56 \\
		& 1.83 & 1.06 & & & \\
		\hline
		sprint late 1 & 91 & 89 & & & 37 \\
		& 11.1 & 7.6 & & & \\
		\hline
		sprint hidden 1 & 35 & 29 & & & 32 \\
		& 3.88 & 3.42 & & & \\
		\hline
	\end{tabular}
	\caption{Average objective values for some instances}
	\label{results}
\end{table}

Lastly, we tried to see what happens to the distribution of $k_N$ and $k_C$.
One thing we perceived in general is that the combination (1,1) is very successful, that is, using the destroy operator with only one nurse and one constraint.
This is a curious result that we had not expected; on the other hand, it should not lead us to the conclusion that fixing the $k$ to these values would be a good idea, as it might only work well when there is a variety between the iterations.

For one particular instance, the final distribution is visualised in figures \ref{finaldist} and \ref{distdiff}.
For this instance, it seems that using the destroy operator with more than 4 constraints at once performs poorly; however, we cannot really generalise beyond this instance.

\begin{figure}
	\includegraphics[width=\linewidth]{"kdist.png"}
	\caption{Final distribution of the $k$s}
	\label{finaldist}
\end{figure}

\begin{figure}
	\includegraphics[width=\linewidth]{"kdist-diff.png"}
	\caption{Changes in the distribution of the $k$s during the algorithm}
	\label{distdiff}
\end{figure}

\section{Conclusion and discussion}

We have presented a simple large-neighbourhood-search algorithm for the nurse rostering problem.
The algorithm seems to achieve reasonable results in most cases, within a rather small amount of time, though unfortunately the results are not comparable with other research on the same problem formulation.
We have investigated various components of our algorithm, although we were not able to firmly establish the added value of one crucial component, namely our constraints-guided repair operator.

In future research, one could investigate whether a more intelligent repair operator that considers multiple columns at once would improve the solution quality.
Another avenue of potential improvement is investigating the impact of different ways of enforcing constraints and of evaluating the impact of changes in the solution.
It is also a possibility worth investigating if our approach can be combined with a two-phase approach seen in other papers.

\printbibliography

\end{document}
